# Gu√≠a: Probar RAG Localmente

Esta gu√≠a te ayudar√° a probar el sistema RAG con tu aplicaci√≥n frontend funcionando.

## üöÄ Inicio R√°pido (Resumen)

1. **Obt√©n API Key**: Groq (https://console.groq.com/) o Gemini (https://aistudio.google.com/apikey)
2. **Configura Backend**: `cd rag-service` ‚Üí Copia `.env.example` a `.env` ‚Üí Agrega tu API key
3. **Inicia Backend**: Ejecuta `start_rag.ps1` o `start_rag.bat` (o manualmente con `uvicorn`)
4. **Configura Frontend**: Agrega `VITE_RAG_API_URL=http://localhost:8001` a tu `.env` en la ra√≠z
5. **Inicia Frontend**: `npm run dev` (si no est√° corriendo)
6. **Prueba**: Abre `http://localhost:5173` y busca la barra de preguntas en el inicio

**¬°Listo!** Ahora puedes hacer preguntas sobre nutrici√≥n y entrenamiento.

---

## üìã Gu√≠a Detallada

## Paso 1: Obtener API Key (Gratis)

Elige una de estas opciones:

### Opci√≥n A: Groq (Recomendado - M√°s r√°pido)
1. Ve a https://console.groq.com/
2. Crea una cuenta (gratis)
3. Ve a "API Keys" y crea una nueva key
4. Copia la key (ej: `gsk_xxxxxxxxxxxxx`)

### Opci√≥n B: Gemini
1. Ve a https://aistudio.google.com/apikey
2. Crea una cuenta (gratis)
3. Crea una nueva API key
4. Copia la key

## Paso 2: Configurar Backend RAG

1. **Entra al directorio del servicio RAG**:
   ```bash
   cd rag-service
   ```

2. **Crea el archivo `.env`**:
   ```bash
   # En Windows PowerShell:
   Copy-Item .env.example .env
   
   # O en Git Bash/CMD:
   copy .env.example .env
   ```

3. **Edita `.env` y agrega tu API key**:
   ```env
   # Para Groq (recomendado):
   GROQ_API_KEY=tu-api-key-aqui
   
   # O para Gemini:
   # GEMINI_API_KEY=tu-api-key-aqui
   # LLM_PROVIDER=gemini
   ```

4. **Instala las dependencias Python**:
   ```bash
   # Si no tienes Python instalado, desc√°rgalo de python.org
   # Crea un entorno virtual (recomendado):
   python -m venv venv
   
   # Activa el entorno virtual:
   # En Windows PowerShell:
   .\venv\Scripts\Activate.ps1
   # En Windows CMD:
   venv\Scripts\activate.bat
   # En Git Bash:
   source venv/Scripts/activate
   
   # Instala dependencias:
   pip install -r requirements.txt
   ```

5. **(Opcional) Agrega PDFs de prueba**:
   - Coloca archivos PDF sobre nutrici√≥n/entrenamiento en `rag-service/data_source/`
   - Si no tienes PDFs, el sistema funcionar√° igual pero con conocimiento general del LLM

## Paso 3: Iniciar el Servicio RAG

### Opci√≥n A: Script Autom√°tico (Windows - M√°s F√°cil)

**PowerShell**:
```powershell
cd rag-service
.\start_rag.ps1
```

**CMD**:
```cmd
cd rag-service
start_rag.bat
```

El script autom√°ticamente:
- Verifica que existe `.env`
- Crea el entorno virtual si no existe
- Instala dependencias si es necesario
- Inicia el servidor

### Opci√≥n B: Manual

En la terminal donde activaste el entorno virtual:

```bash
cd rag-service
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

Deber√≠as ver:
```
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
INFO:     Started reloader process
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

**¬°Mant√©n esta terminal abierta!** El servicio debe estar corriendo.

## Paso 4: Configurar Frontend

1. **Abre otra terminal** en la ra√≠z del proyecto (`c:\Users\VICTUS\Documents\2026\gym`)

2. **Verifica/crea tu archivo `.env`** en la ra√≠z del proyecto:
   ```env
   # Si ya tienes .env, agrega esta l√≠nea:
   VITE_RAG_API_URL=http://localhost:8001
   
   # Si no existe, copia desde env.example.txt y agrega la l√≠nea de arriba
   ```

3. **Inicia el frontend** (si no est√° corriendo):
   ```bash
   npm run dev
   ```

   Deber√≠as ver algo como:
   ```
   VITE v5.x.x  ready in xxx ms
   ‚ûú  Local:   http://localhost:5173/
   ```

## Paso 5: Probar la Funcionalidad

1. **Abre tu navegador** en `http://localhost:5173`

2. **Inicia sesi√≥n** en tu aplicaci√≥n

3. **Ve a la p√°gina de inicio** (Home)

4. **Busca la barra de preguntas**:
   - Debe aparecer debajo de la navegaci√≥n de fechas
   - Arriba de "Progreso de hoy"
   - Con el t√≠tulo "Pregunta sobre nutrici√≥n y entrenamiento"

5. **Haz una pregunta de prueba**:
   - Ejemplo: "¬øCu√°ntas prote√≠nas necesito al d√≠a?"
   - Haz clic en el bot√≥n de env√≠o (√≠cono de flecha)
   - Deber√≠as ver la respuesta aparecer

6. **Prueba preguntas de seguimiento**:
   - Despu√©s de la primera respuesta, pregunta algo relacionado
   - Ejemplo: "¬øY si hago ejercicio 5 veces por semana?"
   - El sistema deber√≠a recordar el contexto

## Soluci√≥n de Problemas

### Error: "GROQ_API_KEY no est√° configurada"
- Verifica que el archivo `rag-service/.env` existe y tiene la key correcta
- Aseg√∫rate de que el servicio RAG se reinici√≥ despu√©s de crear el `.env`

### Error: "Failed to fetch" en el frontend
- Verifica que el servicio RAG est√° corriendo en el puerto 8001
- Abre `http://localhost:8001/health` en el navegador - deber√≠a devolver `{"status":"ok"}`
- Verifica que `VITE_RAG_API_URL=http://localhost:8001` est√° en tu `.env` del frontend
- Reinicia el servidor de desarrollo (`npm run dev`)

### Error: CORS
- El backend ya tiene CORS configurado para `localhost:5173`
- Si usas otro puerto, edita `rag-service/main.py` y agrega tu puerto a `allow_origins`

### El servicio RAG no inicia
- Verifica que Python 3.10+ est√° instalado: `python --version`
- Verifica que todas las dependencias se instalaron: `pip list | grep llama-index`
- Revisa los errores en la terminal del servicio RAG

### No aparecen respuestas
- Abre la consola del navegador (F12) y revisa errores
- Verifica que el servicio RAG responde: `curl http://localhost:8001/health`
- Revisa los logs del servicio RAG en la terminal

## Verificaci√≥n R√°pida

Para verificar que todo est√° funcionando:

1. **Backend RAG**:
   ```bash
   curl http://localhost:8001/health
   # Debe devolver: {"status":"ok"}
   ```

2. **Frontend**:
   - Abre `http://localhost:5173`
   - Deber√≠as ver la barra de preguntas en el inicio

3. **Test completo**:
   - Haz una pregunta en la barra
   - Deber√≠as ver la respuesta aparecer

## Notas Importantes

- **Dos terminales necesarias**: Una para el backend RAG (puerto 8001) y otra para el frontend (puerto 5173)
- **Primera ejecuci√≥n**: El servicio RAG indexar√° los PDFs la primera vez (puede tardar unos minutos)
- **Sin PDFs**: El sistema funcionar√° igual, pero responder√° con conocimiento general del LLM
- **Historial**: El historial de conversaci√≥n se mantiene durante la sesi√≥n del navegador

## Siguiente Paso

Una vez que funcione localmente, puedes:
- Agregar m√°s PDFs a `rag-service/data_source/`
- Personalizar el modelo LLM en `rag-service/ai_engine.py`
- Desplegar el servicio RAG en producci√≥n (ver `DEPLOY_COMPLETO.md`)
